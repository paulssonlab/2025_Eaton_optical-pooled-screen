{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature processing for timeseries analysis\n",
    "\n",
    "- This notebook is focused on analyzing the mean behavior of the library, over time\n",
    "\n",
    "- It outputs a timeseries dataframe and a steady state dataframe\n",
    "\n",
    "- Most steady state analysis is in another notebook, however"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/de64/micromamba/envs/crispri/lib/python3.10/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.0' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "  var py_version = '3.2.2'.replace('rc', '-rc.').replace('.dev', '-dev.');\n",
       "  var is_dev = py_version.indexOf(\"+\") !== -1 || py_version.indexOf(\"-\") !== -1;\n",
       "  var reloading = false;\n",
       "  var Bokeh = root.Bokeh;\n",
       "  var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n",
       "\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks;\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "    if (js_modules == null) js_modules = [];\n",
       "    if (js_exports == null) js_exports = {};\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    if (!reloading) {\n",
       "      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    }\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "    window._bokeh_on_load = on_load\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    var skip = [];\n",
       "    if (window.requirejs) {\n",
       "      window.requirejs.config({'packages': {}, 'paths': {'jspanel': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/jspanel', 'jspanel-modal': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal', 'jspanel-tooltip': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip', 'jspanel-hint': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint', 'jspanel-layout': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout', 'jspanel-contextmenu': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu', 'jspanel-dock': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@7.2.3/dist/gridstack-all', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'jspanel': {'exports': 'jsPanel'}, 'gridstack': {'exports': 'GridStack'}}});\n",
       "      require([\"jspanel\"], function(jsPanel) {\n",
       "\twindow.jsPanel = jsPanel\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-modal\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-tooltip\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-hint\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-layout\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-contextmenu\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-dock\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"gridstack\"], function(GridStack) {\n",
       "\twindow.GridStack = GridStack\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"notyf\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      root._bokeh_is_loading = css_urls.length + 9;\n",
       "    } else {\n",
       "      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n",
       "    }\n",
       "\n",
       "    var existing_stylesheets = []\n",
       "    var links = document.getElementsByTagName('link')\n",
       "    for (var i = 0; i < links.length; i++) {\n",
       "      var link = links[i]\n",
       "      if (link.href != null) {\n",
       "\texisting_stylesheets.push(link.href)\n",
       "      }\n",
       "    }\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      if (existing_stylesheets.indexOf(url) !== -1) {\n",
       "\ton_load()\n",
       "\tcontinue;\n",
       "      }\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }    if (((window['jsPanel'] !== undefined) && (!(window['jsPanel'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/jspanel.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/gridstack/gridstack@7.2.3/dist/gridstack-all.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    var existing_scripts = []\n",
       "    var scripts = document.getElementsByTagName('script')\n",
       "    for (var i = 0; i < scripts.length; i++) {\n",
       "      var script = scripts[i]\n",
       "      if (script.src != null) {\n",
       "\texisting_scripts.push(script.src)\n",
       "      }\n",
       "    }\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (var i = 0; i < js_modules.length; i++) {\n",
       "      var url = js_modules[i];\n",
       "      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (const name in js_exports) {\n",
       "      var url = js_exports[name];\n",
       "      if (skip.indexOf(url) >= 0 || root[name] != null) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      element.textContent = `\n",
       "      import ${name} from \"${url}\"\n",
       "      window.${name} = ${name}\n",
       "      window._bokeh_on_load()\n",
       "      `\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    if (!js_urls.length && !js_modules.length) {\n",
       "      on_load()\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.2.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.2.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.2.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.2.2.min.js\", \"https://cdn.holoviz.org/panel/1.2.3/dist/panel.min.js\"];\n",
       "  var js_modules = [];\n",
       "  var js_exports = {};\n",
       "  var css_urls = [];\n",
       "  var inline_js = [    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {} // ensure no trailing comma for IE\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }\n",
       "      // Cache old bokeh versions\n",
       "      if (Bokeh != undefined && !reloading) {\n",
       "\tvar NewBokeh = root.Bokeh;\n",
       "\tif (Bokeh.versions === undefined) {\n",
       "\t  Bokeh.versions = new Map();\n",
       "\t}\n",
       "\tif (NewBokeh.version !== Bokeh.version) {\n",
       "\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n",
       "\t}\n",
       "\troot.Bokeh = Bokeh;\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    }\n",
       "    root._bokeh_is_initializing = false\n",
       "  }\n",
       "\n",
       "  function load_or_wait() {\n",
       "    // Implement a backoff loop that tries to ensure we do not load multiple\n",
       "    // versions of Bokeh and its dependencies at the same time.\n",
       "    // In recent versions we use the root._bokeh_is_initializing flag\n",
       "    // to determine whether there is an ongoing attempt to initialize\n",
       "    // bokeh, however for backward compatibility we also try to ensure\n",
       "    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n",
       "    // before older versions are fully initialized.\n",
       "    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n",
       "      root._bokeh_is_initializing = false;\n",
       "      root._bokeh_onload_callbacks = undefined;\n",
       "      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n",
       "      load_or_wait();\n",
       "    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n",
       "      setTimeout(load_or_wait, 100);\n",
       "    } else {\n",
       "      Bokeh = root.Bokeh;\n",
       "      bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n",
       "      root._bokeh_is_initializing = true\n",
       "      root._bokeh_onload_callbacks = []\n",
       "      if (!reloading && (!bokeh_loaded || is_dev)) {\n",
       "\troot.Bokeh = undefined;\n",
       "      }\n",
       "      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n",
       "\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "\trun_inline_js();\n",
       "      });\n",
       "    }\n",
       "  }\n",
       "  // Give older versions of the autoload script a head-start to ensure\n",
       "  // they initialize before we start loading newer version.\n",
       "  setTimeout(load_or_wait, 100)\n",
       "}(window));"
      ],
      "application/vnd.holoviews_load.v0+json": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n  var py_version = '3.2.2'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  var is_dev = py_version.indexOf(\"+\") !== -1 || py_version.indexOf(\"-\") !== -1;\n  var reloading = false;\n  var Bokeh = root.Bokeh;\n  var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      run_callbacks();\n      return null;\n    }\n    if (!reloading) {\n      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {'jspanel': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/jspanel', 'jspanel-modal': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal', 'jspanel-tooltip': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip', 'jspanel-hint': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint', 'jspanel-layout': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout', 'jspanel-contextmenu': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu', 'jspanel-dock': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@7.2.3/dist/gridstack-all', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'jspanel': {'exports': 'jsPanel'}, 'gridstack': {'exports': 'GridStack'}}});\n      require([\"jspanel\"], function(jsPanel) {\n\twindow.jsPanel = jsPanel\n\ton_load()\n      })\n      require([\"jspanel-modal\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-tooltip\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-hint\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-layout\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-contextmenu\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-dock\"], function() {\n\ton_load()\n      })\n      require([\"gridstack\"], function(GridStack) {\n\twindow.GridStack = GridStack\n\ton_load()\n      })\n      require([\"notyf\"], function() {\n\ton_load()\n      })\n      root._bokeh_is_loading = css_urls.length + 9;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    var existing_stylesheets = []\n    var links = document.getElementsByTagName('link')\n    for (var i = 0; i < links.length; i++) {\n      var link = links[i]\n      if (link.href != null) {\n\texisting_stylesheets.push(link.href)\n      }\n    }\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      if (existing_stylesheets.indexOf(url) !== -1) {\n\ton_load()\n\tcontinue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    if (((window['jsPanel'] !== undefined) && (!(window['jsPanel'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/jspanel.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/gridstack/gridstack@7.2.3/dist/gridstack-all.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    var existing_scripts = []\n    var scripts = document.getElementsByTagName('script')\n    for (var i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n\texisting_scripts.push(script.src)\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      var url = js_exports[name];\n      if (skip.indexOf(url) >= 0 || root[name] != null) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.2.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.2.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.2.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.2.2.min.js\", \"https://cdn.holoviz.org/panel/1.2.3/dist/panel.min.js\"];\n  var js_modules = [];\n  var js_exports = {};\n  var css_urls = [];\n  var inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n\tvar NewBokeh = root.Bokeh;\n\tif (Bokeh.versions === undefined) {\n\t  Bokeh.versions = new Map();\n\t}\n\tif (NewBokeh.version !== Bokeh.version) {\n\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n\t}\n\troot.Bokeh = Bokeh;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      Bokeh = root.Bokeh;\n      bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      if (!reloading && (!bokeh_loaded || is_dev)) {\n\troot.Bokeh = undefined;\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n\trun_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "if ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n",
       "  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n",
       "}\n",
       "\n",
       "\n",
       "    function JupyterCommManager() {\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n",
       "      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        comm_manager.register_target(comm_id, function(comm) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        });\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        });\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n",
       "          var messages = comm.messages[Symbol.asyncIterator]();\n",
       "          function processIteratorResult(result) {\n",
       "            var message = result.value;\n",
       "            console.log(message)\n",
       "            var content = {data: message.data, comm_id};\n",
       "            var buffers = []\n",
       "            for (var buffer of message.buffers || []) {\n",
       "              buffers.push(new DataView(buffer))\n",
       "            }\n",
       "            var metadata = message.metadata || {};\n",
       "            var msg = {content, buffers, metadata}\n",
       "            msg_handler(msg);\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "          return messages.next().then(processIteratorResult);\n",
       "        })\n",
       "      }\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n",
       "      if (comm_id in window.PyViz.comms) {\n",
       "        return window.PyViz.comms[comm_id];\n",
       "      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n",
       "        if (msg_handler) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        }\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n",
       "        comm.open();\n",
       "        if (msg_handler) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        }\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        var comm_promise = google.colab.kernel.comms.open(comm_id)\n",
       "        comm_promise.then((comm) => {\n",
       "          window.PyViz.comms[comm_id] = comm;\n",
       "          if (msg_handler) {\n",
       "            var messages = comm.messages[Symbol.asyncIterator]();\n",
       "            function processIteratorResult(result) {\n",
       "              var message = result.value;\n",
       "              var content = {data: message.data};\n",
       "              var metadata = message.metadata || {comm_id};\n",
       "              var msg = {content, metadata}\n",
       "              msg_handler(msg);\n",
       "              return messages.next().then(processIteratorResult);\n",
       "            }\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "        }) \n",
       "        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n",
       "          return comm_promise.then((comm) => {\n",
       "            comm.send(data, metadata, buffers, disposeOnDone);\n",
       "          });\n",
       "        };\n",
       "        var comm = {\n",
       "          send: sendClosure\n",
       "        };\n",
       "      }\n",
       "      window.PyViz.comms[comm_id] = comm;\n",
       "      return comm;\n",
       "    }\n",
       "    window.PyViz.comm_manager = new JupyterCommManager();\n",
       "    \n",
       "\n",
       "\n",
       "var JS_MIME_TYPE = 'application/javascript';\n",
       "var HTML_MIME_TYPE = 'text/html';\n",
       "var EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\n",
       "var CLASS_NAME = 'output';\n",
       "\n",
       "/**\n",
       " * Render data to the DOM node\n",
       " */\n",
       "function render(props, node) {\n",
       "  var div = document.createElement(\"div\");\n",
       "  var script = document.createElement(\"script\");\n",
       "  node.appendChild(div);\n",
       "  node.appendChild(script);\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when a new output is added\n",
       " */\n",
       "function handle_add_output(event, handle) {\n",
       "  var output_area = handle.output_area;\n",
       "  var output = handle.output;\n",
       "  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "    return\n",
       "  }\n",
       "  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "  if (id !== undefined) {\n",
       "    var nchildren = toinsert.length;\n",
       "    var html_node = toinsert[nchildren-1].children[0];\n",
       "    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var scripts = [];\n",
       "    var nodelist = html_node.querySelectorAll(\"script\");\n",
       "    for (var i in nodelist) {\n",
       "      if (nodelist.hasOwnProperty(i)) {\n",
       "        scripts.push(nodelist[i])\n",
       "      }\n",
       "    }\n",
       "\n",
       "    scripts.forEach( function (oldScript) {\n",
       "      var newScript = document.createElement(\"script\");\n",
       "      var attrs = [];\n",
       "      var nodemap = oldScript.attributes;\n",
       "      for (var j in nodemap) {\n",
       "        if (nodemap.hasOwnProperty(j)) {\n",
       "          attrs.push(nodemap[j])\n",
       "        }\n",
       "      }\n",
       "      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n",
       "      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n",
       "      oldScript.parentNode.replaceChild(newScript, oldScript);\n",
       "    });\n",
       "    if (JS_MIME_TYPE in output.data) {\n",
       "      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n",
       "    }\n",
       "    output_area._hv_plot_id = id;\n",
       "    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n",
       "      window.PyViz.plot_index[id] = Bokeh.index[id];\n",
       "    } else {\n",
       "      window.PyViz.plot_index[id] = null;\n",
       "    }\n",
       "  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "    var bk_div = document.createElement(\"div\");\n",
       "    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var script_attrs = bk_div.children[0].attributes;\n",
       "    for (var i = 0; i < script_attrs.length; i++) {\n",
       "      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "    }\n",
       "    // store reference to server id on output_area\n",
       "    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when an output is cleared or removed\n",
       " */\n",
       "function handle_clear_output(event, handle) {\n",
       "  var id = handle.cell.output_area._hv_plot_id;\n",
       "  var server_id = handle.cell.output_area._bokeh_server_id;\n",
       "  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n",
       "  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n",
       "  if (server_id !== null) {\n",
       "    comm.send({event_type: 'server_delete', 'id': server_id});\n",
       "    return;\n",
       "  } else if (comm !== null) {\n",
       "    comm.send({event_type: 'delete', 'id': id});\n",
       "  }\n",
       "  delete PyViz.plot_index[id];\n",
       "  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n",
       "    var doc = window.Bokeh.index[id].model.document\n",
       "    doc.clear();\n",
       "    const i = window.Bokeh.documents.indexOf(doc);\n",
       "    if (i > -1) {\n",
       "      window.Bokeh.documents.splice(i, 1);\n",
       "    }\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle kernel restart event\n",
       " */\n",
       "function handle_kernel_cleanup(event, handle) {\n",
       "  delete PyViz.comms[\"hv-extension-comm\"];\n",
       "  window.PyViz.plot_index = {}\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle update_display_data messages\n",
       " */\n",
       "function handle_update_output(event, handle) {\n",
       "  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n",
       "  handle_add_output(event, handle)\n",
       "}\n",
       "\n",
       "function register_renderer(events, OutputArea) {\n",
       "  function append_mime(data, metadata, element) {\n",
       "    // create a DOM node to render to\n",
       "    var toinsert = this.create_output_subarea(\n",
       "    metadata,\n",
       "    CLASS_NAME,\n",
       "    EXEC_MIME_TYPE\n",
       "    );\n",
       "    this.keyboard_manager.register_events(toinsert);\n",
       "    // Render to node\n",
       "    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "    render(props, toinsert[0]);\n",
       "    element.append(toinsert);\n",
       "    return toinsert\n",
       "  }\n",
       "\n",
       "  events.on('output_added.OutputArea', handle_add_output);\n",
       "  events.on('output_updated.OutputArea', handle_update_output);\n",
       "  events.on('clear_output.CodeCell', handle_clear_output);\n",
       "  events.on('delete.Cell', handle_clear_output);\n",
       "  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n",
       "\n",
       "  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "    safe: true,\n",
       "    index: 0\n",
       "  });\n",
       "}\n",
       "\n",
       "if (window.Jupyter !== undefined) {\n",
       "  try {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  } catch(err) {\n",
       "  }\n",
       "}\n"
      ],
      "application/vnd.holoviews_load.v0+json": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div class=\"logo-block\">\n",
       "<img src='data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAYAAACqaXHeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAAB+wAAAfsBxc2miwAAABl0RVh0U29mdHdhcmUAd3d3Lmlua3NjYXBlLm9yZ5vuPBoAAA6zSURB\n",
       "VHic7ZtpeFRVmsf/5966taWqUlUJ2UioBBJiIBAwCZtog9IOgjqACsogKtqirT2ttt069nQ/zDzt\n",
       "tI4+CrJIREFaFgWhBXpUNhHZQoKBkIUASchWla1S+3ar7r1nPkDaCAnZKoQP/D7mnPOe9/xy76n3\n",
       "nFSAW9ziFoPFNED2LLK5wcyBDObkb8ZkxuaoSYlI6ZcOKq1eWFdedqNzGHQBk9RMEwFAASkk0Xw3\n",
       "ETacDNi2vtvc7L0ROdw0AjoSotQVkKSvHQz/wRO1lScGModBFbDMaNRN1A4tUBCS3lk7BWhQkgpD\n",
       "lG4852/+7DWr1R3uHAZVQDsbh6ZPN7CyxUrCzJMRouusj0ipRwD2uKm0Zn5d2dFwzX1TCGhnmdGo\n",
       "G62Nna+isiUqhkzuKrkQaJlPEv5mFl2fvGg2t/VnzkEV8F5ioioOEWkLG86fvbpthynjdhXYZziQ\n",
       "x1hC9J2NFyi8vCTt91Fh04KGip0AaG9zuCk2wQCVyoNU3Hjezee9bq92duzzTmxsRJoy+jEZZZYo\n",
       "GTKJ6SJngdJqAfRzpze0+jHreUtPc7gpBLQnIYK6BYp/uGhw9YK688eu7v95ysgshcg9qSLMo3JC\n",
       "4jqLKQFBgdKDPoQ+Pltb8dUyQLpeDjeVgI6EgLIQFT5tEl3rn2losHVsexbZ3EyT9wE1uGdkIPcy\n",
       "BGxn8QUq1QrA5nqW5i2tLqvrrM9NK6AdkVIvL9E9bZL/oyfMVd/jqvc8LylzRBKDJSzIExwhQzuL\n",
       "QYGQj4rHfFTc8mUdu3E7yoLtbTe9gI4EqVgVkug2i5+uXGo919ixbRog+3fTbQ8qJe4ZOYNfMoTI\n",
       "OoshUNosgO60AisX15aeI2PSIp5KiFLI9ubb1vV3Qb2ltwLakUCDAkWX7/nHKRmmGIl9VgYsUhJm\n",
       "2NXjKYADtM1ygne9QQDIXlk49FBstMKx66D1v4+XuQr7vqTe0VcBHQlRWiOCbmmSYe2SqtL6q5rJ\n",
       "zsTb7lKx3FKOYC4DoqyS/B5bvLPxvD9Qtf6saxYLQGJErmDOdOMr/zo96km1nElr8bmPOBwI9COv\n",
       "HnFPRIwmkSOv9kcAS4heRsidOkpeWBgZM+UBrTFAXNYL5Vf2ii9c1trNzpYdaoVil3WIc+wdk+gQ\n",
       "noie3ecCcxt9ITcLAPWt/laGEO/9U6PmzZkenTtsSMQ8uYywJVW+grCstAvCIaAdArAsIWkRDDs/\n",
       "KzLm2YcjY1Lv0UdW73HabE9n6V66cxSzfEmuJssTpKGVp+0vHq73FwL46eOjpMpbRAnNmJFrGJNu\n",
       "Ukf9Yrz+3rghiumCKNXXWPhLYcjxGsIpoCMsIRoFITkW8AuyM8jC1+/QLx4bozCEJIq38+1rtpR6\n",
       "V/yzb8eBlRb3fo5l783N0CWolAzJHaVNzkrTzlEp2bQ2q3TC5gn6wpnoQAmwSiGh2GitnTmVMc5O\n",
       "UyfKWUKCIsU7+fZDKwqdT6DDpvkzAX4/+AMFjk0tDp5GRXLpQ2MUmhgDp5gxQT8+Y7hyPsMi8uxF\n",
       "71H0oebujHALECjFKaW9Lm68n18wXp2kVzIcABytD5iXFzg+WVXkegpAsOOYziqo0OkK76GyquC3\n",
       "ltZAzMhhqlSNmmWTE5T6e3IN05ITFLM4GdN0vtZ3ob8Jh1NAKXFbm5PtLU/eqTSlGjkNAJjdgn/N\n",
       "aedXa0tdi7+t9G0FIF49rtMSEgAs1kDLkTPO7ebm4IUWeyh1bKomXqlgMG6kJmHcSM0clYLJ8XtR\n",
       "1GTnbV3F6I5wCGikAb402npp1h1s7LQUZZSMIfALFOuL3UUrfnS8+rez7v9qcold5tilgHbO1fjK\n",
       "9ubb17u9oshxzMiUBKXWqJNxd+fqb0tLVs4lILFnK71H0Ind7uiPgACVcFJlrb0tV6DzxqqTIhUM\n",
       "CwDf1/rrVhTa33/3pGPxJYdQ2l2cbgVcQSosdx8uqnDtbGjh9SlDVSMNWhlnilfqZk42Th2ZpLpf\n",
       "xrHec5e815zrr0dfBZSwzkZfqsv+1FS1KUknUwPARVvItfKUY+cn57yP7qv07UE3p8B2uhUwLk09\n",
       "e0SCOrK+hbdYHYLjRIl71wWzv9jpEoeOHhGRrJAzyEyNiJuUqX0g2sBN5kGK6y2Blp5M3lsB9Qh4\n",
       "y2Ja6x6+i0ucmKgwMATwhSjdUu49tKrQ/pvN5d53ml2CGwCmJipmKjgmyuaXzNeL2a0AkQ01Th5j\n",
       "2DktO3Jyk8f9vcOBQHV94OK+fPumJmvQHxJoWkaKWq9Vs+yUsbq0zGT1I4RgeH2b5wef7+c7bl8F\n",
       "eKgoHVVZa8ZPEORzR6sT1BzDUAD/d9F78e2Tzv99v8D+fLVTqAKAsbGamKey1Mt9Ann4eH3gTXTz\n",
       "idWtAJ8PQWOk7NzSeQn/OTHDuEikVF1R4z8BQCy+6D1aWRfY0tTGG2OM8rRoPaeIj5ZHzJxszElN\n",
       "VM8K8JS5WOfv8mzRnQAKoEhmt8gyPM4lU9SmBK1MCQBnW4KONT86v1hZ1PbwSXPw4JWussVjtH9Y\n",
       "NCoiL9UoH/6PSu8jFrfY2t36erQHXLIEakMi1SydmzB31h3GGXFDFNPaK8Rme9B79Ixrd0WN+1ij\n",
       "NRQ/doRmuFLBkHSTOm5GruG+pFjFdAmorG4IXH1Qua6ASniclfFtDYt+oUjKipPrCQB7QBQ2lrgP\n",
       "fFzm+9XWUtcqJ3/5vDLDpJ79XHZk3u8nGZ42qlj1+ydtbxysCezrydp6ugmipNJ7WBPB5tydY0jP\n",
       "HaVNzs3QzeE4ZpTbI+ZbnSFPbVOw9vsfnVvqWnirPyCNGD08IlqtYkh2hjZ5dErEQzoNm+6ykyOt\n",
       "Lt5/PQEuSRRKo22VkydK+vvS1XEKlhCJAnsqvcVvH7f/ZU2R67eXbMEGAMiIV5oWZWiWvz5Fv2xG\n",
       "sjqNJQRvn3Rs2lji/lNP19VjAQDgD7FHhujZB9OGqYxRkZxixgRDVlqS6uEOFaJUVu0rPFzctrnF\n",
       "JqijImVp8dEKVWyUXDk92zAuMZ6bFwpBU1HrOw6AdhQgUooChb0+ItMbWJitSo5Ws3IAOGEOtL53\n",
       "0vHZih9sC4vtofZ7Qu6523V/fmGcds1TY3V36pUsBwAbSlxnVh2xLfAD/IAIMDf7XYIkNmXfpp2l\n",
       "18rkAJAy9HKFaIr/qULkeQQKy9zf1JgDB2uaeFNGijo5QsUyacNUUTOnGO42xSnv4oOwpDi1zYkc\n",
       "efUc3I5Gk6PhyTuVKaOGyLUAYPGIoY9Pu/atL/L92+4q9wbflRJ2Trpm/jPjdBtfnqB/dIThcl8A\n",
       "KG7hbRuKnb8qsQsVvVlTrwQAQMUlf3kwJI24Z4JhPMtcfng5GcH49GsrxJpGvvHIaeem2ma+KSjQ\n",
       "lIwUdYyCY8j4dE1KzijNnIP2llF2wcXNnsoapw9XxsgYAl6k+KzUXbi2yP3KR2ecf6z3BFsBICdW\n",
       "nvnIaG3eHybqX7vbpEqUMT+9OL4Qpe8VON7dXuFd39v19FoAABRVePbGGuXTszO0P7tu6lghUonE\n",
       "llRdrhArLvmKdh9u29jcFiRRkfLUxBiFNiqSU9icoZQHo5mYBI1MBgBH6wMNb+U7Pnw337H4gi1Y\n",
       "ciWs+uks3Z9fztUvfzxTm9Ne8XXkvQLHNytOOZeiD4e0PgkAIAYCYknKUNUDSXEKzdWNpnil7r4p\n",
       "xqkjTarZMtk/K8TQ6Qve78qqvXurGwIJqcOUKfUWHsm8KGvxSP68YudXq4pcj39X49uOK2X142O0\n",
       "Tz5/u/7TVybqH0rSya6ZBwD21/gubbrgWdDgEOx9WUhfBaC2ibcEBYm7a7x+ukrBMNcEZggyR0TE\n",
       "T8zUPjikQ4VosQZbTpS4vqizBKvqmvjsqnpfzaZyx9JPiz1/bfGKdgD45XB1zoIMzYbfTdS/NClB\n",
       "Gct0USiY3YL/g0LHy/uq/Ef6uo5+n0R/vyhp17Klpge763f8rMu6YU/zrn2nml+2WtH+Z+5IAAFc\n",
       "2bUTdTDOSNa9+cQY7YLsOIXhevEkCvzph7a8laecz/Un/z4/Ae04XeL3UQb57IwU9ZDr9UuKVajv\n",
       "nxp1+1UVIo/LjztZkKH59fO3G/JemqCfmaCRqbqbd90ZZ8FfjtkfAyD0J/9+C2h1hDwsSxvGjNDc\n",
       "b4zk5NfrSwiQblLHzZhg+Jf4aPlUwpDqkQqa9nimbt1/TDH8OitGMaQnj+RJS6B1fbF7SY1TqO5v\n",
       "/v0WAADl1f7zokgS7s7VT2DZ7pegUjBM7mjtiDZbcN4j0YrHH0rXpCtY0qPX0cVL0rv5jv/ZXend\n",
       "0u/EESYBAFBU4T4Qa5TflZOhTe7pmKpaP8kCVUVw1+yhXfJWvn1P3hnXi33JsTN6PnP3hHZ8Z3/h\n",
       "aLHzmkNPuPj7Bc/F/Q38CwjTpSwQXgE4Vmwry9tpfq/ZFgqFMy4AVDtCvi8rvMvOmv0N4YwbVgEA\n",
       "sPM72/KVnzfspmH7HQGCRLG2yL1+z8XwvPcdCbsAANh+xPzstgMtxeGKt+6MK3/tacfvwhWvIwMi\n",
       "oKEBtm0H7W+UVfkc/Y1V0BhoPlDr/w1w/eu1vjIgAgDg22OtX6/eYfnEz/focrZTHAFR+PSs56/7\n",
       "q32nwpjazxgwAQCwcU/T62t3WL7r6/jVRa6/byp1rei+Z98ZUAEAhEPHPc8fKnTU9nbgtnOe8h0l\n",
       "9hcGIqmODLQAHCy2Xti6v/XNRivf43f4fFvIteu854+VHnR7q9tfBlwAAGz+pnndB9vM26UebAe8\n",
       "SLHujPOTPVW+rwY+sxskAAC2HrA8t2Vvc7ffP1r9o+vwR2dcr92InIAbKKC1FZ5tB1tf+/G8p8sv\n",
       "N/9Q5zd/XR34LYCwV5JdccMEAMDBk45DH243r/X4xGvqxFa/GNpS7n6rwOwNWwHVE26oAADYurf1\n",
       "zx/utOzt+DMKYM0p17YtZZ5VNzqfsB2HewG1WXE8PoZ7gOclbTIvynZf9JV+fqZtfgs/8F/Nu5rB\n",
       "EIBmJ+8QRMmpU7EzGRsf2FzuePqYRbzh/zE26EwdrT10f6r6o8HOYzCJB9Dpff8tbnGLG8L/A/WE\n",
       "roTBs2RqAAAAAElFTkSuQmCC'\n",
       "     style='height:25px; border-radius:12px; display: inline-block; float: left; vertical-align: middle'></img>\n",
       "\n",
       "\n",
       "  <img src='data:image/png;base64,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'\n",
       "       style='height:15px; border-radius:12px; display: inline-block; float: left'></img>\n",
       "  \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import trenchripper.trenchripper as tr\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import sklearn as skl\n",
    "import dask.dataframe as dd\n",
    "\n",
    "import scipy.stats\n",
    "import dask\n",
    "import warnings\n",
    "import random\n",
    "\n",
    "from dask.distributed import wait\n",
    "from statsmodels.nonparametric import kernel_regression\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "dask_sample_seed = 42\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "dask_wd = \"/home/de64/scratch/de64/dask\"\n",
    "warnings.filterwarnings(action='once',category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_l_norm(x,right_tail_only=False):\n",
    "    if right_tail_only:\n",
    "        x_median = np.nanmedian(x)\n",
    "        x_vals = x[x>x_median]\n",
    "    else:\n",
    "        x_vals = x\n",
    "    l_norm = sp.stats.yeojohnson_normmax(x_vals)\n",
    "    return l_norm\n",
    "\n",
    "def apply_transform(final_output_df_filtered,yeo_subsample = 1,dask_sample_seed=dask_sample_seed,early_time_cutoff=28800,steady_state_time_cutoff=64800,clipping_range=(-4,4),\\\n",
    "                    params_to_transform = ['Division: major_axis_length'], transform_list=[\"YJ-Right\"], time_label=\"time (s)\",trenchid_label=\"Multi-Experiment Phenotype Trenchid\",\\\n",
    "                   gmm_scaling=True):\n",
    "    \n",
    "    subsample_df = final_output_df_filtered.sample(frac=yeo_subsample, random_state = dask_sample_seed).persist()\n",
    "    subsample_df_final = subsample_df[subsample_df[time_label]>=steady_state_time_cutoff]\n",
    "    subsample_df_init = subsample_df[subsample_df[time_label]<early_time_cutoff]\n",
    "    for i,param in enumerate(params_to_transform):\n",
    "        print(param)\n",
    "        transform = transform_list[i]\n",
    "        param_vals_final = subsample_df_final[param].astype(float).compute().tolist()\n",
    "        param_vals_final = np.array(param_vals_final)\n",
    "        param_vals_final = param_vals_final[~np.isnan(param_vals_final)]\n",
    "\n",
    "        param_vals_init = subsample_df_init[param].astype(float).compute().tolist()\n",
    "        param_vals_init = np.array(param_vals_init)\n",
    "        param_vals_init = param_vals_init[~np.isnan(param_vals_init)]\n",
    "\n",
    "        ### extract high variance GMM component\n",
    "        # Fit a Gaussian Mixture Model with two components\n",
    "        X = param_vals_final[:,np.newaxis]\n",
    "        if gmm_scaling:\n",
    "            gmm = skl.mixture.GaussianMixture(n_components=2, random_state=dask_sample_seed)\n",
    "            gmm.fit(X)\n",
    "            \n",
    "            covars = gmm.covariances_[:,0,0]\n",
    "            max_var_component = np.argmax(covars)\n",
    "                   \n",
    "            probs = gmm.predict_proba(X)\n",
    "            weights = probs[:, max_var_component]\n",
    "            ### generate a weighted sample from this component\n",
    "            weighted_sample = np.random.choice(X.flatten(), size=len(X), p=weights/weights.sum())\n",
    "        else:\n",
    "            weighted_sample = X.flatten()\n",
    "\n",
    "        if transform == \"YJ\" or transform == \"YJ-Right\":\n",
    "            if transform == \"YJ\":\n",
    "                l_norm = get_l_norm(weighted_sample,right_tail_only=False)\n",
    "            elif transform == \"YJ-Right\":\n",
    "                l_norm = get_l_norm(weighted_sample,right_tail_only=True)\n",
    "            final_output_df_filtered[param + \": Transformed\"] = final_output_df_filtered[param].apply(lambda x: sp.stats.yeojohnson(x,lmbda = l_norm), meta=(param + \": Transformed\",float)).persist()\n",
    "            transformed_weighted_sample = sp.stats.yeojohnson(weighted_sample,lmbda=l_norm)\n",
    "            transformed_initial_values = sp.stats.yeojohnson(param_vals_init,lmbda=l_norm)\n",
    "        elif transform == \"None\":\n",
    "            final_output_df_filtered[param + \": Transformed\"] = final_output_df_filtered[param]\n",
    "            transformed_weighted_sample = weighted_sample\n",
    "            transformed_initial_values = param_vals_init\n",
    "\n",
    "        weighted_sigma = np.std(transformed_weighted_sample)\n",
    "        median_val = np.median(transformed_initial_values)\n",
    "        feature_scores = (1.35*((final_output_df_filtered[param + \": Transformed\"] - median_val)/weighted_sigma))\n",
    "        feature_scores = np.clip(feature_scores,clipping_range[0],clipping_range[1])\n",
    "        final_output_df_filtered[param + \": Transformed: z score\"] = feature_scores.persist()\n",
    "        \n",
    "    final_output_df_filtered = final_output_df_filtered.reset_index().set_index(trenchid_label,drop=True,sorted=True)\n",
    "    return final_output_df_filtered\n",
    "\n",
    "def timeseries_kernel_reg(df, y_label, min_tpt, max_tpt, kernel_bins, kernel_bandwidth, nan_filter, time_label=\"Final time (s)\", trenchid_label=\"Multi-Experiment Phenotype Trenchid\"):\n",
    "    def kernel_reg(x_arr,y_arr,nan_filter,start=min_tpt,end=max_tpt,kernel_bins=kernel_bins,kernel_bandwidth=kernel_bandwidth):\n",
    "        intervals = np.linspace(start, end, num=kernel_bins, dtype=float)\n",
    "        try:\n",
    "            if nan_filter:\n",
    "                nan_mask = ~np.isnan(y_arr)\n",
    "                y_arr = y_arr[nan_mask]\n",
    "                x_arr = x_arr[nan_mask]\n",
    "            if len(x_arr)>0:\n",
    "                w = kernel_regression.KernelReg(y_arr,x_arr,\"c\",reg_type=\"lc\",bw=np.array([kernel_bandwidth]),ckertype=\"gaussian\").fit(intervals)[0]\n",
    "                reg_x, reg_y = (intervals, w)\n",
    "            else:\n",
    "                reg_x, reg_y = (intervals, [np.NaN for idx in range(len(intervals))])\n",
    "        except:\n",
    "            reg_x, reg_y = (intervals, [np.NaN for idx in range(len(intervals))])\n",
    "        return reg_x, reg_y\n",
    "    kernel_result = df.groupby(trenchid_label).apply(lambda x: list(kernel_reg(x[time_label].values,x[y_label].values,nan_filter)[1]),meta=(y_label, object),)\n",
    "    return kernel_result\n",
    "\n",
    "\n",
    "def get_all_kernel_regs(df, y_label_list, nan_filter_list=[], min_tpt = 0, max_tpt = 36000, kernel_bins=20, kernel_bandwidth = 7200, time_label=\"Cell Cycle\", trenchid_label=\"Multi-Experiment Phenotype Trenchid\"):\n",
    "    out_df = []\n",
    "    for y_label in y_label_list:\n",
    "        sub_df = df[[y_label,time_label]]\n",
    "        \n",
    "        if y_label in nan_filter_list:\n",
    "            kernel_result = timeseries_kernel_reg(sub_df, y_label, min_tpt, max_tpt, kernel_bins, kernel_bandwidth, True, time_label=time_label, trenchid_label=trenchid_label)\n",
    "        else:\n",
    "            kernel_result = timeseries_kernel_reg(sub_df, y_label, min_tpt, max_tpt, kernel_bins, kernel_bandwidth, False, time_label=time_label, trenchid_label=trenchid_label)\n",
    "        kernel_result = kernel_result\n",
    "        kernel_result.name = \"Kernel Trace: \" + y_label\n",
    "        out_df.append(kernel_result)\n",
    "    out_df = dd.concat(out_df, axis=1)\n",
    "    return out_df\n",
    "\n",
    "def explode_kernel_trace(series_x):\n",
    "    output = series_x.apply(lambda x: eval(x)).explode().to_frame()\n",
    "    return output\n",
    "\n",
    "def agg_sem(x,vector):\n",
    "    arr = np.array([eval(item) for item in x[vector].tolist()])\n",
    "    sem_arr = sp.stats.sem(arr, axis=0, nan_policy='propagate')\n",
    "    sem_arr[np.isnan(sem_arr)] = -1\n",
    "    output = sem_arr.tolist()\n",
    "    return output\n",
    "\n",
    "def unpack_sem(x):\n",
    "    sem_arr = np.array(eval(x))\n",
    "    sem_arr[sem_arr==-1] = np.NaN\n",
    "    return sem_arr\n",
    "\n",
    "## need a jankknife mean function\n",
    "def agg_sem_jackknife(x):\n",
    "    sem_arr = sp.stats.sem(np.array(x.values.tolist()),axis=0,nan_policy='propagate')\n",
    "    sem_arr[np.isnan(sem_arr)] = -1\n",
    "    output = sem_arr.tolist()\n",
    "    return output\n",
    "\n",
    "def unpack_sem_jackknife(x):\n",
    "    sem_arr = np.array(eval(x))\n",
    "    sem_arr[sem_arr==-1] = np.NaN\n",
    "    return sem_arr\n",
    "\n",
    "def get_jackknife_mean(jackknife_df_temp_path,jackknife_i,jackknife_ttl):\n",
    "    jackknife_df = pd.read_pickle(jackknife_df_temp_path)\n",
    "    indices_to_drop = jackknife_df.index[jackknife_i::jackknife_ttl]\n",
    "    jackknife_df = jackknife_df.drop(indices_to_drop)\n",
    "    single_jackknife = jackknife_df.groupby(\"oDEPool7_id\")[\"Feature Vector\"].apply(lambda x: np.mean(np.array(x.values.tolist()),axis=0).tolist())\n",
    "    single_jackknife = single_jackknife.to_frame()\n",
    "    jackknife_sem = jackknife_df.groupby(\"oDEPool7_id\")[\"Feature Vector\"].apply(lambda x: agg_sem_jackknife(x))    \n",
    "    single_jackknife[\"SEM: Feature Vector\"] = jackknife_sem\n",
    "    single_jackknife[\"Jackknife\"] = jackknife_i\n",
    "    return single_jackknife\n",
    "\n",
    "def get_mean_var_and_cv(df,final_columns,columns_to_apply_aggregation,sgrna_key='oDEPool7_id'):\n",
    "    sgrna_sorted = df.reset_index(drop=True).set_index(sgrna_key).persist()\n",
    "    sgrna_groupby = sgrna_sorted.groupby(sgrna_key)\n",
    "    mean_df = sgrna_groupby[columns_to_apply_aggregation].apply(lambda x: np.mean(x,axis=0)).compute()\n",
    "    std_df = sgrna_groupby[columns_to_apply_aggregation].apply(lambda x: np.std(x,axis=0,ddof=1)).compute()\n",
    "    cv_df = std_df/mean_df\n",
    "    var_df = sgrna_groupby[columns_to_apply_aggregation].apply(lambda x: np.var(x,axis=0)).compute()\n",
    "    count_df = sgrna_groupby[columns_to_apply_aggregation].apply(lambda x: x.count()).compute()\n",
    "    sem_df = std_df/np.sqrt(count_df)\n",
    "        \n",
    "    mean_df = mean_df.rename(columns={key: \"Mean: \" + key for key in mean_df.columns.tolist()})\n",
    "    var_df = var_df.rename(columns={key: \"Variance: \" + key for key in var_df.columns.tolist()})\n",
    "    cv_df = cv_df.rename(columns={key: \"CV: \" + key for key in cv_df.columns.tolist()})\n",
    "    sem_df = sem_df.rename(columns={key: \"SEM: \" + key for key in sem_df.columns.tolist()})\n",
    "    \n",
    "    output_df = sgrna_groupby.first().compute()\n",
    "    output_df = output_df[final_columns]\n",
    "    output_df = output_df.join(mean_df)\n",
    "    output_df = output_df.join(var_df)\n",
    "    output_df = output_df.join(cv_df)\n",
    "    output_df = output_df.join(sem_df)\n",
    "    \n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Data Processing (Mean Timeseries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230m\n",
      "04:00:00\n"
     ]
    }
   ],
   "source": [
    "# dask_controller = tr.trcluster.dask_controller(\n",
    "#     walltime=\"04:00:00\",\n",
    "#     local=False,\n",
    "#     n_workers=300,\n",
    "#     n_workers_min=200,\n",
    "#     memory=\"16GB\",\n",
    "#     working_directory=dask_wd,\n",
    "# )\n",
    "# dask_controller.startdask()\n",
    "\n",
    "dask_controller = tr.trcluster.dask_controller(\n",
    "    walltime=\"04:00:00\",\n",
    "    local=False,\n",
    "    n_workers=100,\n",
    "    n_workers_min=100,\n",
    "    memory=\"16GB\",\n",
    "    working_directory=dask_wd,\n",
    ")\n",
    "dask_controller.startdask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"http://10.120.16.184:8787/status\">Dashboard</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dask_controller.displaydashboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel regression on each trench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_size = \"500MB\"\n",
    "\n",
    "cell_cycle_df = dd.read_parquet(\"/home/de64/scratch/de64/sync_folder/2021-11-12_lDE20_Validation_1/2024-01-12_Lineage_Cell_Cycle_Merged\", engine=\"pyarrow\",calculate_divisions=True)\n",
    "timepoints_df = dd.read_parquet(\"/home/de64/scratch/de64/sync_folder/2021-11-12_lDE20_Validation_1/2024-01-12_Lineage_Observations_Merged\", engine=\"pyarrow\",calculate_divisions=True)\n",
    "growth_df = dd.read_parquet(\"/home/de64/scratch/de64/sync_folder/2021-11-12_lDE20_Validation_1/2024-01-12_Lineage_Growth_Observations_Merged\", engine=\"pyarrow\",calculate_divisions=True)\n",
    "\n",
    "cell_cycle_df = cell_cycle_df.repartition(partition_size = partition_size)\n",
    "timepoints_df = timepoints_df.repartition(partition_size = partition_size)\n",
    "growth_df = growth_df.repartition(partition_size = partition_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_cycle_params = ['Birth: Length', 'Division: Length',\n",
    "   'Delta: Length', 'Birth: Width',\n",
    "   'Division: Width', 'Delta: Width',\n",
    "   'Birth: Volume', 'Division: Volume', 'Delta: Volume',\n",
    "   'Final timepoints', 'Delta Timepoints', 'Final time (s)',\n",
    "   'Delta time (s)','Septum Displacement','Septum Displacement Length Normalized']\n",
    "timepoints_params = ['area','Length', 'Width', 'Volume','mCherry mean_intensity']\n",
    "growth_params = ['Instantaneous Growth Rate: Volume', 'Instantaneous Growth Rate: Length']\n",
    "all_traced_params = cell_cycle_params + timepoints_params + growth_params\n",
    "all_traced_params = [\"Kernel Trace: \" + item for item in all_traced_params]\n",
    "\n",
    "bandwidth_hours = 2\n",
    "kernel_bins = 20\n",
    "\n",
    "cell_cycle_kernel_df = get_all_kernel_regs(\n",
    "    cell_cycle_df,\n",
    "    cell_cycle_params,\n",
    "    min_tpt = 0,\n",
    "    max_tpt = 36000,\n",
    "    kernel_bins = kernel_bins,\n",
    "    kernel_bandwidth = bandwidth_hours*3600,\n",
    "    time_label=\"Mid-Cycle time (s)\",\n",
    "    trenchid_label=\"Multi-Experiment Phenotype Trenchid\")\n",
    "cell_cycle_kernel_df = cell_cycle_kernel_df.persist()\n",
    "wait(cell_cycle_kernel_df);\n",
    "\n",
    "timepoints_kernel_df = get_all_kernel_regs(\n",
    "    timepoints_df,\n",
    "    timepoints_params,\n",
    "    min_tpt = 0,\n",
    "    max_tpt = 36000,\n",
    "    kernel_bins = kernel_bins,\n",
    "    kernel_bandwidth = bandwidth_hours*3600,\n",
    "    time_label=\"Observation time (s)\",\n",
    "    trenchid_label=\"Multi-Experiment Phenotype Trenchid\")\n",
    "timepoints_kernel_df = timepoints_kernel_df.persist()\n",
    "wait(timepoints_kernel_df);\n",
    "\n",
    "growth_kernel_df = get_all_kernel_regs(\n",
    "    growth_df,\n",
    "    growth_params,\n",
    "    min_tpt = 0,\n",
    "    max_tpt = 36000,\n",
    "    kernel_bins = kernel_bins,\n",
    "    kernel_bandwidth = bandwidth_hours*3600,\n",
    "    time_label=\"Measurement time (s)\",\n",
    "    trenchid_label=\"Multi-Experiment Phenotype Trenchid\")\n",
    "growth_kernel_df = growth_kernel_df.persist()\n",
    "wait(growth_kernel_df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/de64/micromamba/envs/crispri/lib/python3.10/site-packages/dask/dataframe/core.py:7086: FutureWarning: Meta is not valid, `map_partitions` and `map_overlap` expects output to be a pandas object. Try passing a pandas object as meta or a dict or tuple representing the (name, dtype) of the columns. In the future the meta you passed will not work.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## nan filter\n",
    "cell_cycle_kernel_nan_filter = cell_cycle_kernel_df.apply(lambda x: \\\n",
    "                            ~np.any([\"nan\" in item for item in x.tolist()]), axis=1, meta=bool).persist()\n",
    "cell_cycle_kernel_df_filtered = cell_cycle_kernel_df[cell_cycle_kernel_nan_filter]\n",
    "filtered_trenchid_indices = cell_cycle_kernel_df_filtered.index.unique().compute()\n",
    "timepoints_kernel_df_filtered = timepoints_kernel_df.loc[filtered_trenchid_indices]\n",
    "growth_kernel_df_filtered = growth_kernel_df.loc[filtered_trenchid_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge Timeseries dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trenchid_label=\"Multi-Experiment Phenotype Trenchid\"\n",
    "\n",
    "cell_cycle_single_trenchid = cell_cycle_df.groupby(trenchid_label).first()\n",
    "timepoints_single_trenchid = timepoints_df.groupby(trenchid_label).first()\n",
    "growth_out_single_trenchid = growth_df.groupby(trenchid_label).first()\n",
    "\n",
    "cell_cycle_out = cell_cycle_kernel_df_filtered.join(cell_cycle_single_trenchid)\n",
    "timepoints_out = timepoints_kernel_df_filtered.join(timepoints_single_trenchid)\n",
    "growth_out = growth_kernel_df_filtered.join(growth_out_single_trenchid)\n",
    "\n",
    "traced_col_names = [col_name for col_name in cell_cycle_out.columns.tolist() if col_name in all_traced_params]\n",
    "cell_cycle_out = cell_cycle_out[['Global CellID', 'File Parquet Index', 'fov', 'row', 'trench',\n",
    "       'initial timepoints', 'File Index', 'File Trench Index', 'CellID',\n",
    "       'Trench Score', 'Mother CellID', 'Daughter CellID 1',\n",
    "       'Daughter CellID 2', 'Sister CellID', 'Centroid X', 'Centroid Y',\n",
    "       'Kymograph File Parquet Index', 'Kymograph FOV Parquet Index',\n",
    "       'FOV Parquet Index', 'Experiment #', 'trenchid'] + traced_col_names]\n",
    "\n",
    "traced_col_names = [col_name for col_name in timepoints_out.columns.tolist() if col_name in all_traced_params]\n",
    "timepoints_out = timepoints_out[traced_col_names]\n",
    "\n",
    "traced_col_names = [col_name for col_name in growth_out.columns.tolist() if col_name in all_traced_params]\n",
    "growth_out = growth_out[traced_col_names]\n",
    "\n",
    "timeseries_merged_dd = dd.concat([cell_cycle_out,timepoints_out,growth_out], axis=1)\n",
    "timeseries_merged_dd = timeseries_merged_dd.repartition(partition_size=partition_size).persist()\n",
    "wait(timeseries_merged_dd);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export Kernel Regression Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kernel_trace_columns = [column_name for column_name in timeseries_merged_dd.columns if \"Kernel Trace\" in column_name]\n",
    "explode_series_list = []\n",
    "for column_name in kernel_trace_columns:\n",
    "    empty_df_ex = pd.DataFrame(data=[],columns=[\"Multi-Experiment Phenotype Trenchid\",column_name]).astype({\"Multi-Experiment Phenotype Trenchid\":int,\\\n",
    "                                                column_name:float}).set_index(\"Multi-Experiment Phenotype Trenchid\")\n",
    "    working_exploded_column = timeseries_merged_dd[column_name].map_partitions(explode_kernel_trace,meta=empty_df_ex)\n",
    "    explode_series_list.append(working_exploded_column)\n",
    "kernel_output_df = dd.concat(explode_series_list, axis=1).persist()\n",
    "wait(kernel_output_df);\n",
    "\n",
    "n_indices = len(timeseries_merged_dd)\n",
    "first_kernel_trace_column = [column_name for column_name in timeseries_merged_dd.columns if \"Kernel Trace\" in column_name][0]\n",
    "timeseries_len = len(eval(timeseries_merged_dd[first_kernel_trace_column].get_partition(0).compute().iloc[0]))\n",
    "timepoint_index = np.tile(range(timeseries_len),n_indices)\n",
    "kernel_output_df = tr.add_list_to_column(kernel_output_df,list(timepoint_index),\"Kernel Timepoints\").persist()\n",
    "wait(kernel_output_df);\n",
    "\n",
    "kernel_output_df = kernel_output_df.reset_index()\n",
    "kernel_output_df[\"Multi-Experiment Phenotype Trenchid-Kernel Timepoint Index\"] =  kernel_output_df.apply(lambda x: int(f'{x[\"Multi-Experiment Phenotype Trenchid\"]:010n}{x[\"Kernel Timepoints\"]:03n}'), axis=1, meta=(None,'int64')).persist()\n",
    "kernel_output_df = kernel_output_df.set_index(\"Multi-Experiment Phenotype Trenchid-Kernel Timepoint Index\",sorted=True)\n",
    "wait(kernel_output_df);\n",
    "\n",
    "kernel_output_df.to_parquet(\"/home/de64/scratch/de64/sync_folder/2021-11-12_lDE20_Validation_1/2024-01-12_Kernel_Regression_df\",\\\n",
    "                            engine=\"pyarrow\",schema='infer',overwrite=True)\n",
    "dask_controller.daskclient.cancel(kernel_output_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "strain_dict = {\"ftsN\":list(range(16)),\\\n",
    "              \"glyQ\":list(range(16,32)),\\\n",
    "              \"rplA\":list(range(32,48)),\\\n",
    "              \"dnaA\":list(range(48,64)),\\\n",
    "              \"mrdA\":list(range(64,80)),\\\n",
    "              \"EV\":list(range(80,96))}\n",
    "inv_strain_dict = {item:key for key,val in strain_dict.items() for item in val}\n",
    "gene_dict = {\"ftsN\":9586,\\\n",
    "             \"glyQ\":7113,\\\n",
    "             \"rplA\":4754,\\\n",
    "             \"dnaA\":8869,\\\n",
    "             \"mrdA\":9865,\\\n",
    "             \"EV\":29672}\n",
    "\n",
    "timeseries_merged_df = timeseries_merged_dd.compute()\n",
    "timeseries_merged_df[\"Gene\"] = timeseries_merged_df[\"fov\"].apply(lambda x: inv_strain_dict[x])\n",
    "timeseries_merged_df[\"oDEPool7_id\"] = timeseries_merged_df[\"Gene\"].apply(lambda x: gene_dict[x])\n",
    "\n",
    "n_obs = timeseries_merged_df.groupby(\"oDEPool7_id\",sort=False).apply(lambda x: len(x.index.unique()), meta=int).compute()\n",
    "n_obs = pd.DataFrame(n_obs).rename({0:\"N Observations\"}, axis=1).sort_index()\n",
    "timeseries_merged_df = timeseries_merged_df.merge(n_obs,on=\"oDEPool7_id\",how='inner',right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregate over timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_sem(x,vector):\n",
    "    arr = np.array([eval(item) for item in x[vector].tolist()])\n",
    "    sem_arr = sp.stats.sem(arr, axis=0, nan_policy='propagate')\n",
    "    sem_arr[np.isnan(sem_arr)] = -1\n",
    "    output = sem_arr.tolist()\n",
    "    return output\n",
    "\n",
    "def unpack_sem(x):\n",
    "    sem_arr = np.array(x)\n",
    "    sem_arr[sem_arr==-1] = np.NaN\n",
    "    return sem_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Trace: Birth: Length\n",
      "Kernel Trace: Division: Length\n",
      "Kernel Trace: Delta: Length\n",
      "Kernel Trace: Birth: Width\n",
      "Kernel Trace: Division: Width\n",
      "Kernel Trace: Delta: Width\n",
      "Kernel Trace: Birth: Volume\n",
      "Kernel Trace: Division: Volume\n",
      "Kernel Trace: Delta: Volume\n",
      "Kernel Trace: Final timepoints\n",
      "Kernel Trace: Delta Timepoints\n",
      "Kernel Trace: Final time (s)\n",
      "Kernel Trace: Delta time (s)\n",
      "Kernel Trace: Septum Displacement\n",
      "Kernel Trace: Septum Displacement Length Normalized\n",
      "Kernel Trace: area\n",
      "Kernel Trace: Length\n",
      "Kernel Trace: Width\n",
      "Kernel Trace: Volume\n",
      "Kernel Trace: mCherry mean_intensity\n",
      "Kernel Trace: Instantaneous Growth Rate: Volume\n",
      "Kernel Trace: Instantaneous Growth Rate: Length\n"
     ]
    }
   ],
   "source": [
    "## params\n",
    "vectors_to_aggregate = all_traced_params\n",
    "\n",
    "timeseries_merged_df_sgRNA_sorted = timeseries_merged_df.set_index(\"oDEPool7_id\").sort_index()\n",
    "timeseries_merged_df_sgRNA_sorted_groupby = timeseries_merged_df_sgRNA_sorted.groupby([\"oDEPool7_id\"])\n",
    "    \n",
    "sgRNA_df_merged = timeseries_merged_df_sgRNA_sorted_groupby.first()\n",
    "\n",
    "for vector in vectors_to_aggregate:\n",
    "    print(vector)\n",
    "    mean_vectors = timeseries_merged_df_sgRNA_sorted_groupby.apply(lambda x: \\\n",
    "            np.mean(np.array([eval(item) for item in x[vector].tolist()]), axis=0))\n",
    "    sgRNA_df_merged[vector] = mean_vectors\n",
    "    \n",
    "    sem_vectors = timeseries_merged_df_sgRNA_sorted_groupby.apply(lambda x: \\\n",
    "            agg_sem(x,vector))\n",
    "    sem_vectors = sem_vectors.apply(lambda x: unpack_sem(x))\n",
    "    sgRNA_df_merged[\"SEM: \" + vector] = sem_vectors\n",
    "\n",
    "sgRNA_df_merged.to_pickle(\"/home/de64/scratch/de64/sync_folder/2021-11-12_lDE20_Validation_1/2024-01-12_sgRNA_Timeseries_df.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Steady State Measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/de64/micromamba/envs/crispri/lib/python3.10/site-packages/dask/dataframe/core.py:7086: FutureWarning: Meta is not valid, `map_partitions` and `map_overlap` expects output to be a pandas object. Try passing a pandas object as meta or a dict or tuple representing the (name, dtype) of the columns. In the future the meta you passed will not work.\n",
      "  warnings.warn(\n",
      "/home/de64/micromamba/envs/crispri/lib/python3.10/site-packages/dask/dataframe/core.py:7086: FutureWarning: Meta is not valid, `map_partitions` and `map_overlap` expects output to be a pandas object. Try passing a pandas object as meta or a dict or tuple representing the (name, dtype) of the columns. In the future the meta you passed will not work.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "strain_dict = {\"ftsN\":list(range(16)),\\\n",
    "              \"glyQ\":list(range(16,32)),\\\n",
    "              \"rplA\":list(range(32,48)),\\\n",
    "              \"dnaA\":list(range(48,64)),\\\n",
    "              \"mrdA\":list(range(64,80)),\\\n",
    "              \"EV\":list(range(80,96))}\n",
    "inv_strain_dict = {item:key for key,val in strain_dict.items() for item in val}\n",
    "gene_dict = {\"ftsN\":9586,\\\n",
    "             \"glyQ\":7113,\\\n",
    "             \"rplA\":4754,\\\n",
    "             \"dnaA\":8869,\\\n",
    "             \"mrdA\":9865,\\\n",
    "             \"EV\":29672}\n",
    "\n",
    "cell_cycle_df = dd.read_parquet(\"/home/de64/scratch/de64/sync_folder/2021-11-12_lDE20_Validation_1/2024-01-12_Lineage_Cell_Cycle_Merged\", engine=\"pyarrow\",calculate_divisions=True)\n",
    "timepoints_df = dd.read_parquet(\"/home/de64/scratch/de64/sync_folder/2021-11-12_lDE20_Validation_1/2024-01-12_Lineage_Observations_Merged\", engine=\"pyarrow\",calculate_divisions=True)\n",
    "growth_df = dd.read_parquet(\"/home/de64/scratch/de64/sync_folder/2021-11-12_lDE20_Validation_1/2024-01-12_Lineage_Growth_Observations_Merged\", engine=\"pyarrow\",calculate_divisions=True)\n",
    "\n",
    "cell_cycle_params = ['Birth: Length', 'Division: Length',\n",
    "   'Delta: Length', 'Birth: Width',\n",
    "   'Division: Width', 'Delta: Width',\n",
    "   'Birth: Volume', 'Division: Volume', 'Delta: Volume',\n",
    "   'Final timepoints', 'Delta Timepoints', 'Final time (s)',\n",
    "   'Delta time (s)','Septum Displacement','Septum Displacement Length Normalized']\n",
    "timepoints_params = ['area','Length', 'Width', 'Volume','mCherry mean_intensity']\n",
    "growth_params = ['Instantaneous Growth Rate: Volume', 'Instantaneous Growth Rate: Length']\n",
    "all_traced_params = cell_cycle_params + timepoints_params + growth_params\n",
    "\n",
    "cell_cycle_df[\"Gene\"] = cell_cycle_df[\"fov\"].apply(lambda x: inv_strain_dict[x], meta=str)\n",
    "cell_cycle_df[\"oDEPool7_id\"] = cell_cycle_df[\"Gene\"].apply(lambda x: gene_dict[x], meta=int)\n",
    "gene_series = cell_cycle_df.groupby(\"Multi-Experiment Phenotype Trenchid\")[\"Gene\"].first().compute()\n",
    "sgrnaid_series = cell_cycle_df.groupby(\"Multi-Experiment Phenotype Trenchid\")[\"oDEPool7_id\"].first().compute()\n",
    "\n",
    "timepoints_df = timepoints_df.join(gene_series)\n",
    "timepoints_df = timepoints_df.join(sgrnaid_series)\n",
    "\n",
    "growth_df = growth_df.join(gene_series)\n",
    "growth_df = growth_df.join(sgrnaid_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Steady State Time to Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "steady_state_time = 8*3600 #8 hours\n",
    "induction_time = 2*3600\n",
    "\n",
    "trenchid_label=\"Multi-Experiment Phenotype Trenchid\"\n",
    "\n",
    "cell_cycle_df_ss = cell_cycle_df[cell_cycle_df[\"Initial time (s)\"]>=steady_state_time]\n",
    "cell_cycle_df_pre = cell_cycle_df[cell_cycle_df[\"Final time (s)\"]<=induction_time]\n",
    "\n",
    "timepoints_df_ss = timepoints_df[timepoints_df[\"Observation time (s)\"]>=steady_state_time]\n",
    "timepoints_df_pre = timepoints_df[timepoints_df[\"Observation time (s)\"]<=induction_time]\n",
    "\n",
    "growth_df_ss = growth_df[growth_df[\"Measurement time (s)\"]>=steady_state_time]\n",
    "growth_df_pre = growth_df[growth_df[\"Measurement time (s)\"]<=induction_time]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add sgRNA info for real data and save as checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/de64/micromamba/envs/crispri/lib/python3.10/site-packages/dask/dataframe/core.py:7086: FutureWarning: Meta is not valid, `map_partitions` and `map_overlap` expects output to be a pandas object. Try passing a pandas object as meta or a dict or tuple representing the (name, dtype) of the columns. In the future the meta you passed will not work.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell Cycle Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/de64/micromamba/envs/crispri/lib/python3.10/site-packages/dask/dataframe/core.py:7086: FutureWarning: Meta is not valid, `map_partitions` and `map_overlap` expects output to be a pandas object. Try passing a pandas object as meta or a dict or tuple representing the (name, dtype) of the columns. In the future the meta you passed will not work.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timepoints Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/de64/micromamba/envs/crispri/lib/python3.10/site-packages/dask/dataframe/core.py:7086: FutureWarning: Meta is not valid, `map_partitions` and `map_overlap` expects output to be a pandas object. Try passing a pandas object as meta or a dict or tuple representing the (name, dtype) of the columns. In the future the meta you passed will not work.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Growth Done.\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "n_obs = cell_cycle_df_ss.groupby(\"oDEPool7_id\",sort=False).apply(lambda x: len(x.index.unique()), meta=int).compute()\n",
    "n_obs = pd.DataFrame(n_obs).rename({0:\"N Observations\"}, axis=1).sort_index()\n",
    "cell_cycle_df_ss = cell_cycle_df_ss.merge(n_obs,on=\"oDEPool7_id\",how='inner')\n",
    "cell_cycle_df_pre = cell_cycle_df_pre.merge(n_obs,on=\"oDEPool7_id\",how='inner')\n",
    "cell_cycle_df_ss.to_parquet(\"/home/de64/scratch/de64/sync_folder/2021-11-12_lDE20_Validation_1/2024-01-13_Lineage_Cell_Cycle_Timeseries_Steady_State/\", engine=\"pyarrow\", overwrite=True)\n",
    "cell_cycle_df_pre.to_parquet(\"/home/de64/scratch/de64/sync_folder/2021-11-12_lDE20_Validation_1/2024-01-13_Lineage_Cell_Cycle_Timeseries_Preinduction/\", engine=\"pyarrow\", overwrite=True)\n",
    "print(\"Cell Cycle Done.\")\n",
    "\n",
    "n_obs = timepoints_df_ss.groupby(\"oDEPool7_id\",sort=False).apply(lambda x: len(x.index.unique()), meta=int).compute()\n",
    "n_obs = pd.DataFrame(n_obs).rename({0:\"N Observations\"}, axis=1).sort_index()\n",
    "timepoints_df_ss = timepoints_df_ss.merge(n_obs,on=\"oDEPool7_id\",how='inner')\n",
    "timepoints_df_pre = timepoints_df_pre.merge(n_obs,on=\"oDEPool7_id\",how='inner')\n",
    "timepoints_df_ss.to_parquet(\"/home/de64/scratch/de64/sync_folder/2021-11-12_lDE20_Validation_1/2024-01-13_Lineage_Timepoints_Timeseries_Steady_State/\", engine=\"pyarrow\", overwrite=True)\n",
    "timepoints_df_pre.to_parquet(\"/home/de64/scratch/de64/sync_folder/2021-11-12_lDE20_Validation_1/2024-01-13_Lineage_Timepoints_Timeseries_Preinduction/\", engine=\"pyarrow\", overwrite=True)\n",
    "print(\"Timepoints Done.\")\n",
    "\n",
    "n_obs = growth_df_ss.groupby(\"oDEPool7_id\",sort=False).apply(lambda x: len(x.index.unique()), meta=int).compute()\n",
    "n_obs = pd.DataFrame(n_obs).rename({0:\"N Observations\"}, axis=1).sort_index()\n",
    "growth_df_ss = growth_df_ss.merge(n_obs,on=\"oDEPool7_id\",how='inner')\n",
    "growth_df_pre = growth_df_pre.merge(n_obs,on=\"oDEPool7_id\",how='inner')\n",
    "growth_df_ss.to_parquet(\"/home/de64/scratch/de64/sync_folder/2021-11-12_lDE20_Validation_1/2024-01-13_Lineage_Growth_Timeseries_Steady_State/\", engine=\"pyarrow\", overwrite=True)\n",
    "growth_df_pre.to_parquet(\"/home/de64/scratch/de64/sync_folder/2021-11-12_lDE20_Validation_1/2024-01-13_Lineage_Growth_Timeseries_Preinduction/\", engine=\"pyarrow\", overwrite=True)\n",
    "print(\"Growth Done.\")\n",
    "dask_controller.reset_worker_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-13 16:33:54,400 - distributed.deploy.adaptive_core - INFO - Adaptive stop\n"
     ]
    }
   ],
   "source": [
    "dask_controller.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
