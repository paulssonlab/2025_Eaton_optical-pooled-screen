Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	chunkfastq
	1

[Tue Jun  4 23:22:15 2024]
rule chunkfastq:
    input: /home/de64/scratch/de64/sync_folder/2024-06-04_NGS_Ploidy_Analysis/fastq_unzipped/LIB062484_GEN00281705_DE19-0Mins-Replicate-1_S1_L001_R1_001.fastq
    output: /home/de64/scratch/de64/sync_folder/2024-06-04_NGS_Ploidy_Analysis/fastq_chunked/LIB062484_GEN00281705_DE19-0Mins-Replicate-1_S1_L001_R1_001
    jobid: 0
    wildcards: samplename=LIB062484_GEN00281705_DE19-0Mins-Replicate-1_S1_L001_R1_001
    resources: partition=short, time_min=60, mem_mb=8000, cpus=1, optflags=

ImproperOutputException in line 23 of /home/de64/paulssonlab/paulssonlab/src/paulssonlab/deaton/nanopore/dev_notebooks/2024-06-04_NGS_Ploidy_Analysis/Snakefile:
Outputs of incorrect type (directories when expecting files or vice versa). Output directories must be flagged with directory(). for rule chunkfastq:
/home/de64/scratch/de64/sync_folder/2024-06-04_NGS_Ploidy_Analysis/fastq_chunked/LIB062484_GEN00281705_DE19-0Mins-Replicate-1_S1_L001_R1_001
  File "/home/de64/micromamba/envs/nanopore/lib/python3.10/site-packages/snakemake/executors/__init__.py", line 566, in handle_job_success
  File "/home/de64/micromamba/envs/nanopore/lib/python3.10/site-packages/snakemake/executors/__init__.py", line 243, in handle_job_success
Removing output files of failed job chunkfastq since they might be corrupted:
/home/de64/scratch/de64/sync_folder/2024-06-04_NGS_Ploidy_Analysis/fastq_chunked/LIB062484_GEN00281705_DE19-0Mins-Replicate-1_S1_L001_R1_001
Skipped removing non-empty directory /home/de64/scratch/de64/sync_folder/2024-06-04_NGS_Ploidy_Analysis/fastq_chunked/LIB062484_GEN00281705_DE19-0Mins-Replicate-1_S1_L001_R1_001
Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
